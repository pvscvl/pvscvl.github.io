<HTML
><HEAD
>
<TITLE>Recipe 20.8. Finding Fresh Links (Perl Cookbook)</TITLE>
<META
NAME="DC.title"
CONTENT="Perl Cookbook"><META
NAME="DC.creator"
CONTENT="Tom Christiansen &amp; Nathan Torkington"><META
NAME="DC.publisher"
CONTENT="O'Reilly &amp; Associates, Inc."><META
NAME="DC.date"
CONTENT="1999-07-02T01:45:59Z"><META
NAME="DC.type"
CONTENT="Text.Monograph"><META
NAME="DC.format"
CONTENT="text/html"
SCHEME="MIME"><META
NAME="DC.source"
CONTENT="1-56592-243-3"
SCHEME="ISBN"><META
NAME="DC.language"
CONTENT="en-US"><META
NAME="generator"
CONTENT="Jade 1.1/O'Reilly DocBook 3.0 to HTML 4.0"><LINK
REV="made"
HREF="mailto:online-books@oreilly.com"
TITLE="Online Books Comments"><LINK
REL="up"
HREF="ch20_01.htm"
TITLE="20. Web Automation"><LINK
REL="prev"
HREF="ch20_08.htm"
TITLE="20.7. Finding Stale Links"><LINK
REL="next"
HREF="ch20_10.htm"
TITLE="20.9. Creating HTML Templates"></HEAD
><BODY
BGCOLOR="#FFFFFF"
TEXT="#000000"
><DIV
CLASS="htmlnav"
><H1
><IMG
SRC="gifs/smbanner.gif"
ALT="Perl Cookbook"
USEMAP="#srchmap"
BORDER="0"></H1
><MAP
NAME="srchmap"
><AREA
SHAPE="RECT"
COORDS="0,0,466,65"
HREF="index.htm"
ALT="Perl Cookbook"><AREA
SHAPE="RECT"
COORDS="467,0,514,18"
HREF="jobjects/fsearch.htm"
ALT="Search this book"></MAP
><TABLE
WIDTH="515"
BORDER="0"
CELLSPACING="0"
CELLPADDING="0"
><TR
><TD
ALIGN="LEFT"
VALIGN="TOP"
WIDTH="172"
><A
CLASS="sect1"
HREF="ch20_08.htm"
TITLE="20.7. Finding Stale Links"
><IMG
SRC="../gifs/txtpreva.gif"
ALT="Previous: 20.7. Finding Stale Links"
BORDER="0"></A
></TD
><TD
ALIGN="CENTER"
VALIGN="TOP"
WIDTH="171"
><B
><FONT
FACE="ARIEL,HELVETICA,HELV,SANSERIF"
SIZE="-1"
><A
CLASS="chapter"
REL="up"
HREF="ch20_01.htm"
TITLE="20. Web Automation"
>Chapter 20<BR>Web Automation</A
></FONT
></B
></TD
><TD
ALIGN="RIGHT"
VALIGN="TOP"
WIDTH="172"
><A
CLASS="sect1"
HREF="ch20_10.htm"
TITLE="20.9. Creating HTML Templates"
><IMG
SRC="../gifs/txtnexta.gif"
ALT="Next: 20.9. Creating HTML Templates"
BORDER="0"></A
></TD
></TR
></TABLE
>&nbsp;<HR
ALIGN="LEFT"
WIDTH="515"
TITLE="footer"></DIV
><DIV
CLASS="sect1"
><H2
CLASS="sect1"
><A
CLASS="title"
NAME="ch20-37341"
>20.8. Finding Fresh Links</A
></H2
><DIV
CLASS="sect2"
><H3
CLASS="sect2"
><A
CLASS="title"
NAME="ch20-pgfId-861"
>Problem<A
CLASS="indexterm"
NAME="ch20-idx-1000002657-0"
></A
></A
></H3
><P
CLASS="para"
><A
CLASS="indexterm"
NAME="ch20-idx-1000003777-0"
></A
><A
CLASS="indexterm"
NAME="ch20-idx-1000003777-1"
></A
>Given a list of URLs, you want to determine which have been most recently modified.</P
></DIV
><DIV
CLASS="sect2"
><H3
CLASS="sect2"
><A
CLASS="title"
NAME="ch20-pgfId-867"
>Solution</A
></H3
><P
CLASS="para"
>The program in <A
CLASS="xref"
HREF="ch20_09.htm"
TITLE="surl"
>Example 20.6</A
> reads URLs from standard input, rearranges by date, and prints them back to standard output with those dates prepended.</P
><DIV
CLASS="example"
><H4
CLASS="example"
><A
CLASS="title"
NAME="ch20-35690"
>Example 20.6: surl</A
></H4
><PRE
CLASS="programlisting"
>#!/usr/bin/perl -w
# surl - sort URLs by their last modification date

use LWP::UserAgent;
use HTTP::Request;
use URI::URL qw(url);

my($url, %Date);
my $ua = LWP::UserAgent-&gt;new();

while ( $url = url(scalar &lt;&gt;) ) {
    my $ans;
    next unless $url-&gt;scheme =~ /^(file|https?)$/;
    $ans = $ua-&gt;request(HTTP::Request-&gt;new(&quot;HEAD&quot;, $url));
    if ($ans-&gt;is_success) {
        $Date{$url} = $ans-&gt;last_modified || 0;  # unknown
    } else {
        print STDERR &quot;$url: Error [&quot;, $ans-&gt;code, &quot;] &quot;, $ans-&gt;message, &quot;!\n&quot;;
    }
}

foreach $url ( sort { $Date{$b} &lt;=&gt; $Date{$a} } keys %Date ) {
    printf &quot;%-25s %s\n&quot;, $Date{$url} ? (scalar localtime $Date{$url})
                                     : &quot;&lt;NONE SPECIFIED&gt;&quot;, $url;
}</PRE
></DIV
></DIV
><DIV
CLASS="sect2"
><H3
CLASS="sect2"
><A
CLASS="title"
NAME="ch20-pgfId-923"
>Discussion</A
></H3
><P
CLASS="para"
>The <A
CLASS="indexterm"
NAME="ch20-idx-1000002659-0"
></A
>surl script works more like a traditional filter program. It reads from standard input one URL per line. (Actually, it reads from &lt;<CODE
CLASS="literal"
>ARGV</CODE
>&gt;, which defaults to STDIN if <CODE
CLASS="literal"
>@ARGV</CODE
> is empty.) The last-modified date on each URL is fetched using a HEAD request. That date is stored in a hash using the URL for a key. Then a simple sort by value is run on the hash to reorder the URLs by date. On output, the internal date is converted into <CODE
CLASS="literal"
>localtime</CODE
> format.</P
><P
CLASS="para"
>Here's an example of using the xurl program from the earlier recipe to extract the URLs, then running that program's output to feed into surl.</P
><PRE
CLASS="programlisting"
>% xurl http://www.perl.com/  | surl | head
<CODE
CLASS="userinput"
><B
><CODE
CLASS="replaceable"
><I
>Mon Apr 20 06:16:02 1998  http://electriclichen.com/linux/srom.html</I
></CODE
></B
></CODE
>
<CODE
CLASS="userinput"
><B
><CODE
CLASS="replaceable"
><I
>Fri Apr 17 13:38:51 1998  http://www.oreilly.com/</I
></CODE
></B
></CODE
>
<CODE
CLASS="userinput"
><B
><CODE
CLASS="replaceable"
><I
>Fri Mar 13 12:16:47 1998  http://www2.binevolve.com/</I
></CODE
></B
></CODE
>
<CODE
CLASS="userinput"
><B
><CODE
CLASS="replaceable"
><I
>Sun Mar  8 21:01:27 1998  http://www.perl.org/</I
></CODE
></B
></CODE
>
<CODE
CLASS="userinput"
><B
><CODE
CLASS="replaceable"
><I
>Tue Nov 18 13:41:32 1997  http://www.perl.com/universal/header.map</I
></CODE
></B
></CODE
>
<CODE
CLASS="userinput"
><B
><CODE
CLASS="replaceable"
><I
>Wed Oct  1 12:55:13 1997  http://www.songline.com/</I
></CODE
></B
></CODE
>
<CODE
CLASS="userinput"
><B
><CODE
CLASS="replaceable"
><I
>Sun Aug 17 21:43:51 1997  http://www.perl.com/graphics/perlhome_header.jpg</I
></CODE
></B
></CODE
>
<CODE
CLASS="userinput"
><B
><CODE
CLASS="replaceable"
><I
>Sun Aug 17 21:43:47 1997  http://www.perl.com/graphics/perl_id_313c.gif</I
></CODE
></B
></CODE
>
<CODE
CLASS="userinput"
><B
><CODE
CLASS="replaceable"
><I
>Sun Aug 17 21:43:46 1997  http://www.perl.com/graphics/ora_logo.gif</I
></CODE
></B
></CODE
>
<CODE
CLASS="userinput"
><B
><CODE
CLASS="replaceable"
><I
>Sun Aug 17 21:43:44 1997  http://www.perl.com/graphics/header-nav.gif</I
></CODE
></B
></CODE
></PRE
><P
CLASS="para"
>Having a variety of small programs that each do one thing and that can be combined into more powerful constructs is the hallmark of good programming. You could even argue that xurl should work on files, and that some other program should actually fetch the URL's contents over the Web to feed into xurl, churl, or surl. That program would probably be called gurl, except that a program by that name already exists: the LWP module suite has a program called lwp-request with aliases HEAD, GET, and POST to run those operations in shell <A
CLASS="indexterm"
NAME="ch20-idx-1000003779-0"
></A
><A
CLASS="indexterm"
NAME="ch20-idx-1000003779-1"
></A
>scripts.<A
CLASS="indexterm"
NAME="ch20-idx-1000002653-0"
></A
><A
CLASS="indexterm"
NAME="ch20-idx-1000002653-1"
></A
><A
CLASS="indexterm"
NAME="ch20-idx-1000002653-2"
></A
><A
CLASS="indexterm"
NAME="ch20-idx-1000002653-3"
></A
><A
CLASS="indexterm"
NAME="ch20-idx-1000002653-4"
></A
></P
></DIV
><DIV
CLASS="sect2"
><H3
CLASS="sect2"
><A
CLASS="title"
NAME="ch20-pgfId-955"
>See Also</A
></H3
><P
CLASS="para"
>The documentation for the CPAN modules LWP::UserAgent, HTTP::Request, and URI::URL; <A
CLASS="xref"
HREF="ch20_08.htm"
TITLE="Finding Stale Links"
>Recipe 20.7</A
></P
></DIV
></DIV
><DIV
CLASS="htmlnav"
><P
></P
><HR
ALIGN="LEFT"
WIDTH="515"
TITLE="footer"><TABLE
WIDTH="515"
BORDER="0"
CELLSPACING="0"
CELLPADDING="0"
><TR
><TD
ALIGN="LEFT"
VALIGN="TOP"
WIDTH="172"
><A
CLASS="sect1"
HREF="ch20_08.htm"
TITLE="20.7. Finding Stale Links"
><IMG
SRC="../gifs/txtpreva.gif"
ALT="Previous: 20.7. Finding Stale Links"
BORDER="0"></A
></TD
><TD
ALIGN="CENTER"
VALIGN="TOP"
WIDTH="171"
><A
CLASS="book"
HREF="index.htm"
TITLE="Perl Cookbook"
><IMG
SRC="../gifs/txthome.gif"
ALT="Perl Cookbook"
BORDER="0"></A
></TD
><TD
ALIGN="RIGHT"
VALIGN="TOP"
WIDTH="172"
><A
CLASS="sect1"
HREF="ch20_10.htm"
TITLE="20.9. Creating HTML Templates"
><IMG
SRC="../gifs/txtnexta.gif"
ALT="Next: 20.9. Creating HTML Templates"
BORDER="0"></A
></TD
></TR
><TR
><TD
ALIGN="LEFT"
VALIGN="TOP"
WIDTH="172"
>20.7. Finding Stale Links</TD
><TD
ALIGN="CENTER"
VALIGN="TOP"
WIDTH="171"
><A
CLASS="index"
HREF="index/idx_0.htm"
TITLE="Book Index"
><IMG
SRC="../gifs/index.gif"
ALT="Book Index"
BORDER="0"></A
></TD
><TD
ALIGN="RIGHT"
VALIGN="TOP"
WIDTH="172"
>20.9. Creating HTML Templates</TD
></TR
></TABLE
><HR
ALIGN="LEFT"
WIDTH="515"
TITLE="footer"><P
CLASS="nav"
><FONT
SIZE="-1"
></P
></DIV
<!-- LIBRARY NAV BAR --> <img src="../gifs/smnavbar.gif" usemap="#library-map" border="0" alt="Library Navigation Links"><p> <a href="copyrght.htm">Copyright &copy; 2001</a> O'Reilly &amp; Associates. All rights reserved.</font> </p> <map name="library-map"> <area shape="rect" coords="2,-1,79,99" href="../index.htm"><area shape="rect" coords="84,1,157,108" href="../perlnut/index.htm"><area shape="rect" coords="162,2,248,125" href="../prog/index.htm"><area shape="rect" coords="253,2,326,130" href="../advprog/index.htm"><area shape="rect" coords="332,1,407,112" href="index.htm"><area shape="rect" coords="414,2,523,103" href="../sysadmin/index.htm"></map> </BODY
></HTML
>
