<html><head>
<title>Recipe 20.11. Creating a Robot</TITLE>
<meta name="DC.title" content="Perl Cookbook"><meta name="DC.creator" content="Tom Christiansen &amp; Nathan Torkington"><meta name="DC.publisher" content="O'Reilly &amp; Associates, Inc."><meta name="DC.date" content="1999-07-02T01:46:02Z"><meta name="DC.type" content="Text.Monograph"><meta name="DC.format" content="text/html" scheme="MIME"><meta name="DC.source" content="1-56592-243-3" scheme="ISBN"><meta name="DC.language" content="en-US"><meta name="generator" content="Jade 1.1/O'Reilly DocBook 3.0 to HTML 4.0"><link rev="made" href="mailto:online-books@oreilly.com" title="Online Books Comments"><link rel="up" href="ch20_01.htm" title="20. Web Automation"><link rel="prev" href="ch20_11.htm" title="20.10. Mirroring Web Pages"><link rel="next" href="ch20_13.htm" title="20.12. Parsing a Web Server Log File"></HEAD
><body bgcolor="#FFFFFF" text="#000000"><div class="htmlnav"><h1><img src="gifs/smbanner.gif" alt="Perl Cookbook" usemap="#srchmap" border="0"></H1
><map name=index.html"srchmap"><area shape="RECT" coords="0,0,466,65" href="index.htm" alt="Perl Cookbook"><area shape="RECT" coords="467,0,514,18" href="../search/csrch.htm" alt="Search this book"></MAP
><table width="515" border="0" cellspacing="0" cellpadding="0"><tr><td align="LEFT" valign="TOP" width="172"><a class="sect1" href="ch20_11.htm" title="20.10. Mirroring Web Pages"><img src="../gifs/txtpreva.gif" alt="Previous: 20.10. Mirroring Web Pages" border="0"></A
></TD
><td align="CENTER" valign="TOP" width="171"><b><font face="ARIEL,HELVETICA,HELV,SANSERIF" size="-1"><a class="chapter" rel="up" href="ch20_01.htm" title="20. Web Automation">Chapter 20<br>Web Automation</A
></FONT
></B
></TD
><td align="RIGHT" valign="TOP" width="172"><a class="sect1" href="ch20_13.htm" title="20.12. Parsing a Web Server Log File"><img src="../gifs/txtnexta.gif" alt="Next: 20.12. Parsing a Web Server Log File" border="0"></A
></TD
></TR
></TABLE
>&nbsp;<hr align="LEFT" width="515" title="footer"></DIV
><div class="sect1"><h2 class="sect1"><a class="title" name="ch20-chap20_creating_1">20.11. Creating a Robot</A
></H2
><div class="sect2"><h3 class="sect2"><a class="title" name="ch20-pgfId-1241">Problem<a class="indexterm" name="ch20-idx-1000002667-0"></A
><a class="indexterm" name="ch20-idx-1000002667-1"></A
><a class="indexterm" name="ch20-idx-1000002667-2"></A
><a class="indexterm" name="ch20-idx-1000002667-3"></A
></A
></H3
><p class="para">You want to create a script that navigates the Web on its own (i.e., a robot), and you'd like to respect the remote sites' wishes.</P
></DIV
><div class="sect2"><h3 class="sect2"><a class="title" name="ch20-pgfId-1247">Solution</A
></H3
><p class="para">Instead of writing your robot to use LWP::UserAgent, have it use <a class="indexterm" name="ch20-idx-1000002668-0"></A
>LWP::RobotUA instead:</P
><pre class="programlisting">use LWP::RobotUA;
$ua = LWP::RobotUA-&gt;new('websnuffler/0.1', 'me@wherever.com');</PRE
></DIV
><div class="sect2"><h3 class="sect2"><a class="title" name="ch20-pgfId-1257">Discussion</A
></H3
><p class="para">To avoid having marauding robots and web crawlers hammer their servers, sites are encouraged to create a file with access rules called robots.txt. If you're fetching only one document with your script, this is no big deal, but if your script is going to fetch many documents, probably from the same server, you could easily exhaust that site's bandwidth.</P
><p class="para">When you create your own scripts to run around the Web, it's important to be a good net citizen. That means two things: don't request documents from the same server too often, and heed the advisory access rules in their robots.txt file.</P
><p class="para">The easiest way to handle this is to use the LWP::RobotUA module to create agents instead of LWP::UserAgent. This agent automatically knows to pull things over slowly when repeatedly calling the same server. It also checks each site's robots.txt file to see whether you're trying to grab a file that is off limits. If you do, you'll get back a response like this:</P
><pre class="programlisting">403 (Forbidden) Forbidden by robots.txt</PRE
><p class="para">Here's an example robots.txt file, fetched using the GET program that comes with the LWP module suite:</P
><pre class="programlisting">% GET http://www.webtechniques.com/robots.txt 
<code class="userinput"><b><code class="replaceable"><i>User-agent: *</I
></CODE
></B
></CODE
>
<code class="userinput"><b><code class="replaceable"><i>     Disallow: /stats</I
></CODE
></B
></CODE
>
<code class="userinput"><b><code class="replaceable"><i>     Disallow: /db</I
></CODE
></B
></CODE
>
<code class="userinput"><b><code class="replaceable"><i>     Disallow: /logs</I
></CODE
></B
></CODE
>
<code class="userinput"><b><code class="replaceable"><i>     Disallow: /store</I
></CODE
></B
></CODE
>
<code class="userinput"><b><code class="replaceable"><i>     Disallow: /forms</I
></CODE
></B
></CODE
>
<code class="userinput"><b><code class="replaceable"><i>     Disallow: /gifs</I
></CODE
></B
></CODE
>
<code class="userinput"><b><code class="replaceable"><i>     Disallow: /wais-src</I
></CODE
></B
></CODE
>
<code class="userinput"><b><code class="replaceable"><i>     Disallow: /scripts</I
></CODE
></B
></CODE
>
<code class="userinput"><b><code class="replaceable"><i>     Disallow: /config</I
></CODE
></B
></CODE
></PRE
><p class="para">A more interesting and extensive example is at <a class="systemitem.url" href="../../../../../../../www.cnn.com/robots.txt.">http://www.cnn.com/robots.txt.</A
> This file is so big, they even keep it under RCS control!</P
><pre class="programlisting">% GET http://www.cnn.com/robots.txt | head
<code class="userinput"><b><code class="replaceable"><i># robots, scram</I
></CODE
></B
></CODE
>
<code class="userinput"><b><code class="replaceable"><i># $I d : robots.txt,v 1.2 1998/03/10 18:27:01 mreed Exp $</I
></CODE
></B
></CODE
>
<code class="userinput"><b><code class="replaceable"><i>User-agent: *</I
></CODE
></B
></CODE
>
<code class="userinput"><b><code class="replaceable"><i>Disallow: /</I
></CODE
></B
></CODE
>
<code class="userinput"><b><code class="replaceable"><i>User-agent:     Mozilla/3.01 (hotwired-test/0.1)</I
></CODE
></B
></CODE
>
<code class="userinput"><b><code class="replaceable"><i>Disallow:   /cgi-bin</I
></CODE
></B
></CODE
>
<code class="userinput"><b><code class="replaceable"><i>Disallow:   /TRANSCRIPTS</I
></CODE
></B
></CODE
>
<code class="userinput"><b><code class="replaceable"><i>Disallow:   /development</I
></CODE
></B
></CODE
><a class="indexterm" name="ch20-idx-1000002670-0"></A
><a class="indexterm" name="ch20-idx-1000002670-1"></A
><a class="indexterm" name="ch20-idx-1000002670-2"></A
><a class="indexterm" name="ch20-idx-1000002670-3"></A
></PRE
></DIV
><div class="sect2"><h3 class="sect2"><a class="title" name="ch20-pgfId-1317">See Also</A
></H3
><p class="para">The documentation for the CPAN module LWP::RobotUA(3); <a class="systemitem.url" href="../../../../../../../info.webcrawler.com/mak/projects/robots/robots.html">http://info.webcrawler.com/mak/projects/robots/robots.html</A
> for a description of how well-behaved robots act</P
></DIV
></DIV
><div class="htmlnav"><p></P
><hr align="LEFT" width="515" title="footer"><table width="515" border="0" cellspacing="0" cellpadding="0"><tr><td align="LEFT" valign="TOP" width="172"><a class="sect1" href="ch20_11.htm" title="20.10. Mirroring Web Pages"><img src="../gifs/txtpreva.gif" alt="Previous: 20.10. Mirroring Web Pages" border="0"></A
></TD
><td align="CENTER" valign="TOP" width="171"><a class="book" href="index.htm" title="Perl Cookbook"><img src="../gifs/txthome.gif" alt="Perl Cookbook" border="0"></A
></TD
><td align="RIGHT" valign="TOP" width="172"><a class="sect1" href="ch20_13.htm" title="20.12. Parsing a Web Server Log File"><img src="../gifs/txtnexta.gif" alt="Next: 20.12. Parsing a Web Server Log File" border="0"></A
></TD
></TR
><tr><td align="LEFT" valign="TOP" width="172">20.10. Mirroring Web Pages</TD
><td align="CENTER" valign="TOP" width="171"><a class="index" href="index/idx_0.htm" title="Book Index"><img src="../gifs/index.gif" alt="Book Index" border="0"></A
></TD
><td align="RIGHT" valign="TOP" width="172">20.12. Parsing a Web Server Log File</TD
></TR
></TABLE
><hr align="LEFT" width="515" title="footer"><p class="nav"><font size="-1">[ <a href="../index.html" title="The Perl CD Bookshelf">Library Home</A
> | <a href="../perlnut/index.htm" title="Perl in a Nutshell">Perl in a Nutshell</A
> | <a href="../learn/index.htm" title="Learning Perl">Learning Perl</A
> | <a href="../learn32/index.htm" title="Learning Perl on Win32 Systems">Learning Perl on Win32</A
> | <a href="../prog/index.htm" title="Programming Perl">Programming Perl</A
> | <a href="../advprog/index.htm" title="Advanced Perl Programming">Advanced Perl Programming</A
> | <a href="index.htm" title="Perl Cookbook">Perl Cookbook</A
> ]</FONT
></P
></DIV
></BODY
></HTML
>
