<html><head>
<title>[Chapter 27] 27.2 Can You Trust Your Suppliers?</TITLE>
<meta name="DC.title" content="Practical UNIX &amp; Internet Security"><meta name="DC.creator" content="Simson Garfinkel &amp; Gene Spafford"><meta name="DC.publisher" content="O'Reilly &amp; Associates, Inc."><meta name="DC.date" content="1999-02-04T00:20:20Z"><meta name="DC.type" content="Text.Monograph"><meta name="DC.format" content="text/html" scheme="MIME"><meta name="DC.source" content="1-56592-148-8" scheme="ISBN"><meta name="DC.language" content="en-US"><meta name="generator" content="Jade 1.1/O'Reilly DocBook 3.0 to HTML 4.0"><link rev="made" href="mailto:online-books@oreilly.com" title="Online Books Comments"><link rel="up" href="ch27_01.htm" title="27. Who Do You Trust?"><link rel="prev" href="ch27_01.htm" title="27.1 Can you Trust Your Computer?"><link rel="next" href="ch27_03.htm#PUIS-CHP-27-SECT-3.3" title="27.3 Can You Trust People?"></HEAD
><body bgcolor="#FFFFFF" text="#000000"><div class="htmlnav"><h1><img src="gifs/smbanner.gif" alt="Practical UNIX &amp; Internet Security" usemap="#srchmap" border="0"></H1
><map namindex.htmle="srchmap"><area shape="RECT" coords="0,0,466,65" href="index.htm" alt="Practical UNIX &amp; Internet Security"><area shape="RECT" coords="467,0,514,18" href="../search/psrch.htm" alt="Search this book"></MAP
><table width="515" border="0" cellspacing="0" cellpadding="0"><tr><td align="LEFT" valign="TOP" width="172"><a class="SECT1" href="ch27_01.htm" title="27.1 Can you Trust Your Computer?"><img src="../gifs/txtpreva.gif" alt="Previous: 27.1 Can you Trust Your Computer?" border="0"></A
></TD
><td align="CENTER" valign="TOP" width="171"><b><font face="ARIEL,HELVETICA,HELV,SANSERIF" size="-1">Chapter 27<br>Who Do You Trust?</FONT
></B
></TD
><td align="RIGHT" valign="TOP" width="172"><a class="SECT1" href="ch27_03.htm#PUIS-CHP-27-SECT-3.3" title="27.3 Can You Trust People?"><img src="../gifs/txtnexta.gif" alt="Next: 27.3 Can You Trust People?" border="0"></A
></TD
></TR
></TABLE
>&nbsp;<hr align="LEFT" width="515" title="footer"></DIV
><div class="SECT1"><h2 class="sect1"><a class="title" name="PUIS-CHP-27-SECT-2">27.2 Can You Trust Your Suppliers?</A
></H2
><p class="para">Your computer does something suspicious. You discover that
the modification dates on your system software have changed. It
appears that an attacker has broken in, or that some kind of virus
is spreading. So what do you do? You save your files to backup tapes,
format your hard disks, and reinstall your computer's operating
system and programs from the original distribution media.</P
><p class="para">Is this really the right plan? You can never know. Perhaps
your problems were the result of a break-in. But sometimes, the
worst is brought to you by the people who sold you your hardware
and software in the first place.</P
><div class="sect2"><h3 class="sect2"><a class="title" name="PUIS-CHP-27-SECT-2.1">27.2.1 Hardware Bugs</A
></H3
><p class="para"><a class="indexterm" name="AUTOID-35790"></A
><a class="indexterm" name="AUTOID-35793"></A
>The fact
that Intel Pentium processors had a floating-point problem that
infrequently resulted in a significant loss of precision when performing
some division operations was revealed to the public in 1994. Not
only had Intel officials known about this, but apparently they had
decided not to tell their customers until after there was significant
negative public reaction.</P
><p class="para">Several vendors of disk drives have had problems with their
products failing suddenly and catastrophically, sometimes within
days of being placed in use. Other disk drives failed when they
were used with <span class="acronym">UNIX</SPAN
>, but not with the vendor's
own proprietary operating system. The reason: <span class="acronym">UNIX</SPAN
>
did not run the necessary command to map out bad blocks on the media.
Yet, these drives were widely bought for use with the <span class="acronym">UNIX</SPAN
>
operating system.</P
><p class="para">Furthermore, there are many cases of effective <i class="filename"><a class="indexterm" name="AUTOID-35802"></A
>self-destruct sequences</I
> in various
kinds of terminals and computers. For example, Digital's
original <a class="indexterm" name="AUTOID-35804"></A
>
VT100 terminal had
an escape sequence that switched the terminal from a 60Hz refresh
rate to a 50Hz refresh rate, and another escape sequence that switched
it back. By repeatedly sending the two escape sequences to a VT100
terminal, a malicious programmer could cause the terminal's
flyback transformer to burn out&nbsp;- sometimes spectacularly!</P
><p class="para">A similar sequence of instructions could be used to break
the monochrome monitor on the original <span class="acronym">IBM</SPAN
> PC
video display.</P
></DIV
><div class="sect2"><h3 class="sect2"><a class="title" name="PUIS-CHP-27-SECT-2.2">27.2.2 Viruses on the Distribution Disk</A
></H3
><p class="para"><a class="indexterm" name="AUTOID-35811"></A
><a class="indexterm" name="AUTOID-35813"></A
>A
few years ago, there was a presumption in the field of computer
security that manufacturers who distributed computer software took
the time and due diligence to ensure that their computer programs,
if not free of bugs and defects, were at least free of computer
viruses and glaring computer security holes. Users were warned not
to run shareware and not to download programs from bulletin board
systems, because such programs were likely to contain viruses or
Trojan horses. Indeed, at least one company, which manufactured
a shareware virus scanning program, made a small fortune telling
the world that everybody else's shareware programs were
potentially unsafe.</P
><p class="para">Time and experience have taught us otherwise.</P
><p class="para">In recent years, a few viruses have been distributed with
shareware, but we have also seen many viruses distributed in shrink-wrapped
programs. The viruses come from small companies, and from the makers
of major computer systems. Even Microsoft distributed a <span class="acronym">CD-ROM</SPAN
>
with a virus hidden inside a macro for Microsoft Word. The Bureau
of the Census distributed a <span class="acronym">CD-ROM</SPAN
> with a virus
on it. One of the problems posed by viruses on distribution disks
is that many installation procedures require that the user disable
any antiviral software that is running.</P
><p class="para">The mass-market software industry has also seen a problem
with <a class="indexterm" name="AUTOID-35822"></A
><a class="indexterm" name="AUTOID-35824"></A
><a class="indexterm" name="AUTOID-35826"></A
><a class="indexterm" name="AUTOID-35829"></A
>
logic bombs and Trojan horses. For example, in
1994, Adobe distributed a version of a new Photoshop 3.0 for the
Macintosh with a &quot;time bomb&quot; designed to make
the program stop working at some point in the future; the time bomb
had inadvertently been left in the program from the beta-testing
cycle. Because commercial software is not distributed in source
code form, you cannot inspect a program and tell if this kind of
intentional bug is present or not.</P
><p class="para">Like shrink-wrapped programs, <a class="indexterm" name="AUTOID-35833"></A
>
shareware
is also a mixed bag. Some shareware sites have system administrators
who are very conscientious, and who go to great pains to scan their
software libraries with viral scanners before making them available
for download. Other sites have no controls, and allow users to place
files directly in the download libraries. In the spring of 1995,
a program called PKZIP30.EXE made its way around a variety of <span class="acronym">FTP</SPAN
>
sites on the Internet and through America Online. This program appeared
to be the 3.0 beta release of <span class="acronym">PKZIP</SPAN
>, a popular
<span class="acronym">DOS</SPAN
> compression utility. But when the program
was run, it erased the user's hard disk.</P
></DIV
><div class="sect2"><h3 class="sect2"><a class="title" name="PUIS-CHP-27-SECT-2.3">27.2.3 Buggy Software</A
></H3
><p class="para"><a class="indexterm" name="AUTOID-35841"></A
>Consider the following, rather
typical, disclaimer on a piece of distributed software:</P
><blockquote class="blockquote"><p class="para">NO WARRANTY OF PERFORMANCE. THE PROGRAM AND ITS
ASSOCIATED DOCUMENTATION ARE LICENSED &quot;AS IS&quot;
WITHOUT WARRANTY AS TO THEIR PERFORMANCE, MERCHANTABILITY, OR FITNESS
FOR ANY PARTICULAR PURPOSE. THE ENTIRE RISK AS TO THE RESULTS AND
PERFORMANCE OF THE PROGRAM IS ASSUMED BY YOU AND YOUR DISTRIBUTEES.
SHOULD THE PROGRAM PROVE DEFECTIVE, YOU AND YOUR DISTRIBUTEES (AND
NOT THE VENDOR) ASSUME THE ENTIRE COST OF ALL NECESSARY SERVICING,
REPAIR, OR CORRECTION.</P
></BLOCKQUOTE
><p class="para">Software sometimes has bugs. You install it on your disk,
and under certain circumstances, it damages your files or returns
incorrect results. The examples are legion. You may think that the
software is infected with a virus&nbsp;- it is certainly behaving
as if it is infected with a virus&nbsp;- but the problem is merely
the result of poor programming.</P
><p class="para">If the creators and vendors of the software don't
have confidence in their own software, why should you? If the vendors
disclaim &quot;...warranty as to [its]
performance, merchantability, or fitness for any particular purpose,&quot;
then why are you paying them money and using their software as a
base for your business?</P
><p class="para">Unfortunately, quality is not a priority for most software
vendors. In most cases, they license the software to you with a
broad disclaimer of warranty (similar to the above) so there is
little incentive for them to be sure that every bug has been eradicated
before they go to market. The attitude is often one of &quot;We'll
fix it in the next release, after the customers have found all the
bugs.&quot; Then they introduce new features with new bugs.
Yet people wait in line at midnight to be the first to buy software
that is full of bugs and may erase their disks when they try to
install it.</P
><p class="para">Other bugs abound. Recall that the first study by Professor
Barton Miller, cited in <a class="xref" href="ch23_01.htm" title="Writing Secure SUID and Network Programs">Chapter 23, <cite class="chapter">Writing Secure SUID and Network Programs</CITE
></A
>,
found that more than one-third of common programs supplied by several
<span class="acronym">UNIX</SPAN
> vendors crashed or hung when they were tested
with a trivial program that generated random input. Five years later,
he reran the tests. The results? Although most vendors had improved
to where &quot;only&quot; one-fourth of the programs crashed,
one vendor's software exhibited a 46% failure
rate! This failure rate was despite wide circulation and publication
of the report, and despite the fact that Miller's team
made the test code available for free to vendors.</P
><p class="para">Most frightening, the testing performed by Miller's
group is one of the simplest, least-effective forms of testing that
can be performed (random, black-box testing). Do vendors do any
reasonable testing at all?</P
><p class="para">Consider the case of a software engineer from a major PC software
vendor who came to Purdue to recruit in 1995. During his presentation,
students reported that he stated that two of the top 10 reasons
to work for his company were &quot;You don't need to
bother with that software engineering stuff&nbsp;- you simply
need to love to code&quot; and &quot;You'd rather
write assembly code than test software.&quot; As you might expect,
the company has developed a reputation for quality problems. What
is surprising is that they continue to be a market leader, year
after year, and that people continue to buy their software.[3]</P
><blockquote class="footnote"><p class="para">[3] The same company introduced a product that responded to a
wrong password being typed three times in a row by prompting the
user with something to the effect of, &quot;You appear to have
set your password to something too difficult to remember. Would
you like to set it to something simpler?&quot; Analysis of this
approach is left as an exercise for the reader.</P
></BLOCKQUOTE
><p class="para">What's your vendor's policy about testing
and good software engineering practices?</P
><p class="para">Or, consider the case of someone who implements security features
without really understanding the &quot;big picture.&quot;
As we noted in &quot;Picking a Random Seed&quot; in <a class="xref" href="ch23_01.htm" title="Writing Secure SUID and Network Programs">Chapter 23</A
>,
a sophisticated encryption algorithm was built into Netscape Navigator
to protect credit card numbers in transit on the network. Unfortunately,
the implementation used a weak initialization of the &quot;random
number&quot; used to generate a system key. The result? Someone
with an account on a client machine could easily obtain enough information
to crack the key in a matter of seconds, using only a small program.</P
></DIV
><div class="sect2"><h3 class="sect2"><a class="title" name="PUIS-CHP-27-SECT-2.4">27.2.4 Hacker Challenges</A
></H3
><p class="para"><a class="indexterm" name="AUTOID-35861"></A
><a class="indexterm" name="AUTOID-35863"></A
><a class="indexterm" name="AUTOID-35866"></A
>Over the past decade,
several vendors have issued public challenges stating that their
systems are secure because they haven't been broken by
&quot;hacker challenges.&quot; Usually, these challenges
involve some vendor putting its system on the Internet and inviting
all comers to take a whack in return for some token prize. Then,
after a few weeks or months, the vendor shuts down the site, proclaims
their product invulnerable, and advertises the results as if they
were a badge of honor. But consider the following:</P
><ul class="itemizedlist"><li class="listitem"><p class="para">Few such &quot;challenges&quot;
are conducted using established testing techniques. They are ad
hoc, random tests.</P
></LI
><li class="listitem"><p class="para">That no problems are found does not mean that no
problems exist. The testers might not have exposed them yet. Or,
the testers might not have recognized them. (Consider how often
software is released with bugs, even after careful scrutiny.) Furthermore,
how do you know that the testers will report what they find? In
some cases, the information may be more valuable to the hackers
later on, after the product has been sold to many customers&nbsp;- because
at that time, they'll have more profitable targets to pursue.</P
></LI
><li class="listitem"><p class="para">Simply because the vendor does not report a successful
penetration does not mean that one did not occur&nbsp;- the vendor
may choose not to report it because it would reflect poorly on the
product. Or, the vendor may not have recognized the penetration.</P
></LI
><li class="listitem"><p class="para">Challenges give potential miscreants some period
to practice breaking the system without penalty. Challenges also
give miscreants an excuse if they are caught trying to break into
the system later (e.g., &quot;We thought the contest was still
going on.&quot;)</P
></LI
><li class="listitem"><p class="para">Seldom do the really good experts, on either side
of the fence, participate in such exercises. Thus, anything done
is usually done by amateurs. (The &quot;honor&quot; of having
won the challenge is not sufficient to lure the good ones into the
challenge. Think about it&nbsp;- good consultants can command
fees of several thousand dollars per day in some cases&nbsp;- why
should they effectively donate their time and names for free advertising?)</P
></LI
></UL
><p class="para">Furthermore, the whole process sends the wrong messages&nbsp;- that
we should build things and then try to break them (rather than building
them right in the first place), or that there is some prestige or
glory in breaking systems. We don't test the strengths
of bridges by driving over them with a variety of cars and trucks
to see if they fail, and pronounce them safe if no collapse occurs
during the test.</P
><p class="para">Some software designers could learn a lot from civil engineers.
So might the rest of us: in ancient times, if a house fell or a
bridge collapsed and injured someone, the engineer who designed
it was crushed to death in the rubble as punishment!</P
><p class="para">Next time you see an advertiser using a challenge to sell
a product, you should ask if the challenger is really giving you
more confidence in the product...or convincing you that the
vendor doesn't have a clue as to how to really design and
test security.</P
><p class="para">If you think that a security challenge builds the right kind
of trust, then get in touch with us. We have these magic pendants.
No one wearing one has ever had a system broken into, despite challenges
to all the computer users who happened to be around when the systems
were developed. Thus, the pendants must be effective at keeping
out hackers. We'll be happy to sell some to you. After
all, we employ the same rigorous testing methodology as your security
software vendors, so our product must be reliable, right?<a class="indexterm" name="AUTOID-35884"></A
><a class="indexterm" name="AUTOID-35886"></A
><a class="indexterm" name="AUTOID-35889"></A
></P
></DIV
><div class="sect2"><h3 class="sect2"><a class="title" name="PUIS-CHP-27-SECT-2.5">27.2.5 Security Bugs that Never Get Fixed</A
></H3
><p class="para"><a class="indexterm" name="AUTOID-35895"></A
>There is also the question of legitimate
software distributed by computer manufacturers that contains glaring
security holes. More than a year after the release of sendmail Version
8, nearly every major <span class="acronym">UNIX</SPAN
> vendor was still distributing
its computers equipped with sendmail Version 5. (Versions 6 and
7 were interim releases which were never released.) While Version
8 had many improvements over Version 5, it also had many critical
security patches. Was the unwillingness of <span class="acronym">UNIX</SPAN
>
vendors to adopt Version&nbsp;8 negligence&nbsp;- a demonstration
of their laissez-faire attitude towards computer security&nbsp;- or
merely a reflection of pressing market conditions?[4]
Are the two really different?</P
><blockquote class="footnote"><p class="para">[4] Or
was the new, &quot;improved&quot; program simply too hard
to configure? At least one vendor told us that it was.</P
></BLOCKQUOTE
><p class="para">How about the case in which many vendors still release versions
of <span class="acronym">TFTP</SPAN
> that, by default, allow remote users
to obtain copies of the password file? What about versions of <span class="acronym">RPC</SPAN
>
that allow users to spoof <span class="acronym">NFS</SPAN
> by using proxy
calls through the <span class="acronym">RPC</SPAN
> system? What about software
that includes a writable <i class="filename">utmp</I
> file that enables
a user to overwrite arbitrary system files? Each of these cases
is a well-known security flaw. In each case, the vendors did not
provide fixes for years&nbsp;- even now, they may not be fixed.</P
><p class="para">Many vendors say that computer security is not a high priority,
because they are not convinced that spending more money on computer
security will pay off for them. Computer companies are rightly concerned
with the amount of money that they spend on computer security. Developing
a more secure computer is an expensive proposition that not every
customer may be willing to pay for. The same level of computer security
may not be necessary for a server on the Internet as for a server
behind a corporate firewall, or on a disconnected network. Furthermore,
increased computer security will not automatically increase sales:
firms that want security generally hire staff who are responsible
for keeping systems secure; users who do not want (or do not understand)
security are usually unwilling to pay for it at any price, and frequently
disable security when it is provided.</P
><p class="para">On the other hand, a computer company is far better equipped
to safeguard the security of its operating system than is an individual
user. One reason is that a computer company has access to the system's
source code. A second reason is that most large companies can easily
devote two or three people to assuring the security of their operating
system, whereas most businesses are hard-pressed to devote even
a single full-time employee to the job of computer security.</P
><p class="para">We believe that computer users are beginning to see system
security and software quality as distinguishing features, much in
the way that they see usability, performance, and new functionality
as features. When a person breaks into a computer, over the Internet
or otherwise, the act reflects poorly on the maker of the software.
We hope that computer companies will soon make software quality
at least as important as new features.</P
></DIV
><div class="sect2"><h3 class="sect2"><a class="title" name="PUIS-CHP-27-SECT-2.6">27.2.6 Network Providers that Network Too Well</A
></H3
><p class="para"><a class="indexterm" name="AUTOID-35913"></A
>Network providers
pose special challenges for businesses and individuals. By their
nature, network providers have computers that connect directly to
your computer network, placing the provider (or perhaps a rogue
employee at the providing company) in an ideal position to launch
an attack against your installation. For consumers, providers are
usually in possession of confidential billing information belonging
to the users. Some providers even have the ability to directly make
charges to a user's credit card or to deduct funds from
a user's bank account.</P
><p class="para">Dan <a class="indexterm" name="AUTOID-35916"></A
>
Geer, a Cambridge-based
computer security professional, tells an interesting story about
an investment brokerage firm that set up a series of direct IP connections
between its clients' computers and the computers at the
brokerage firm. The purpose of the links was to allow the clients
to trade directly on the brokerage firm's computer system.
But as the client firms were also competitors, the brokerage house
equipped the link with a variety of sophisticated firewall systems.</P
><p class="para">It turns out, says Geer, that although the firm had protected
itself from its clients, it did not invest the time or money to
protect the clients from each other. One of the firm's
clients proceeded to use the direct connection to break into the
system operated by another client. A significant amount of proprietary
information was stolen before the intrusion was discovered.</P
><p class="para">In another case, a series of articles appearing in <em class="emphasis">The
New York Times</EM
> during the first few months of 1995 revealed
how hacker Kevin <a class="indexterm" name="AUTOID-35921"></A
>
Mitnick allegedly
broke into a computer system operated by Netcom Communications.
One of the things that Mitnick is alleged to have stolen was a complete
copy of Netcom's client database, including the credit
card numbers for more than 30,000 of Netcom's customers.
Certainly, Netcom needed the credit card numbers to bill its customers
for service. But why were they placed on a computer system that
could be reached from the Internet? Why were they not encrypted?</P
><p class="para">Think about all those services that are sprouting up on the
World Wide Web. They claim to use all kinds of super encryption
protocols to safeguard your credit card number as it is sent across
the network. But remember&nbsp;- you can reach their machines
via the Internet to make the transaction. What kinds of safeguards
do they have in place at their sites to protect all the card numbers
after they're collected? If you saw an armored car transferring
your bank's receipts to a &quot;vault&quot; housed
in a cardboard box on a park bench, would the strength of the armored
car cause you to trust the safety of the funds?</P
></DIV
></DIV
><div class="htmlnav"><p></P
><hr align="LEFT" width="515" title="footer"><table width="515" border="0" cellspacing="0" cellpadding="0"><tr><td align="LEFT" valign="TOP" width="172"><a class="SECT1" href="ch27_01.htm" title="27.1 Can you Trust Your Computer?"><img src="../gifs/txtpreva.gif" alt="Previous: 27.1 Can you Trust Your Computer?" border="0"></A
></TD
><td align="CENTER" valign="TOP" width="171"><a class="book" href="index.htm" title="Practical UNIX &amp; Internet Security"><img src="../gifs/txthome.gif" alt="Practical UNIX &amp; Internet Security" border="0"></A
></TD
><td align="RIGHT" valign="TOP" width="172"><a class="SECT1" href="ch27_03.htm#PUIS-CHP-27-SECT-3.3" title="27.3 Can You Trust People?"><img src="../gifs/txtnexta.gif" alt="Next: 27.3 Can You Trust People?" border="0"></A
></TD
></TR
><tr><td align="LEFT" valign="TOP" width="172">27.1 Can you Trust Your Computer?</TD
><td align="CENTER" valign="TOP" width="171"><a class="index" href="index/idx_0.htm" title="Book Index"><img src="../gifs/index.gif" alt="Book Index" border="0"></A
></TD
><td align="RIGHT" valign="TOP" width="172">27.3 Can You Trust People?</TD
></TR
></TABLE
><hr align="LEFT" width="515" title="footer"><p class="nav"><font size="-1">[ <a href="../index.htm" title="The Networking CD Bookshelf">Library Home</A
> | <a href="../dnsbind/index.htm" title="DNS &amp; BIND">DNS &amp; BIND</A
> | <a href="../tcpip/index.htm" title="TCP/IP Network Administration">TCP/IP</A
> | <a href="../sendmail/index.htm" title="sendmail">sendmail</A
> | <a href="../smdref/index.htm" title="sendmail Desktop Reference">sendmail Reference</A
> | <a href="../firewall/index.htm" title="Building Internet Firewalls">Firewalls</A
> | <a href="index.htm" title="Practical UNIX &amp; Internet Security">Practical Security</A
> ]</FONT
></P
></DIV
></BODY
></HTML
>
