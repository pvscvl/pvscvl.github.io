<html><head>
<title>[Chapter 27] Who Do You Trust?</TITLE>
<meta name="DC.title" content="Practical UNIX &amp; Internet Security"><meta name="DC.creator" content="Simson Garfinkel &amp; Gene Spafford"><meta name="DC.publisher" content="O'Reilly &amp; Associates, Inc."><meta name="DC.date" content="1999-02-04T00:20:17Z"><meta name="DC.type" content="Text.Monograph"><meta name="DC.format" content="text/html" scheme="MIME"><meta name="DC.source" content="1-56592-148-8" scheme="ISBN"><meta name="DC.language" content="en-US"><meta name="generator" content="Jade 1.1/O'Reilly DocBook 3.0 to HTML 4.0"><link rev="made" href="mailto:online-books@oreilly.com" title="Online Books Comments"><link rel="up" href="part06.htm" title="VI. Handling Security Incidents"><link rel="prev" href="ch26_04.htm#PUIS-CHP-26-SECT-4.6" title="26.4 Other Liability"><link rel="next" href="ch27_02.htm#PUIS-CHP-27-SECT-2.4" title="27.2 Can You Trust Your Suppliers?"></HEAD
><body bgcolor="#FFFFFF" text="#000000"><div class="htmlnav"><h1><img src="gifs/smbanner.gif" alt="Practical UNIX &amp; Internet Security" usemap="#srchmap" border="0"></H1
><map name="srchmap"index.html><area shape="RECT" coords="0,0,466,65" href="index.htm" alt="Practical UNIX &amp; Internet Security"><area shape="RECT" coords="467,0,514,18" href="../search/psrch.htm" alt="Search this book"></MAP
><table width="515" border="0" cellspacing="0" cellpadding="0"><tr><td align="LEFT" valign="TOP" width="172"><a class="SECT1" href="ch26_04.htm#PUIS-CHP-26-SECT-4.6" title="26.4 Other Liability"><img src="../gifs/txtpreva.gif" alt="Previous: 26.4 Other Liability" border="0"></A
></TD
><td align="CENTER" valign="TOP" width="171"><b><font face="ARIEL,HELVETICA,HELV,SANSERIF" size="-1">Chapter 27</FONT
></B
></TD
><td align="RIGHT" valign="TOP" width="172"><a class="SECT1" href="ch27_02.htm#PUIS-CHP-27-SECT-2.4" title="27.2 Can You Trust Your Suppliers?"><img src="../gifs/txtnexta.gif" alt="Next: 27.2 Can You Trust Your Suppliers?" border="0"></A
></TD
></TR
></TABLE
>&nbsp;<hr align="LEFT" width="515" title="footer"></DIV
><div class="CHAPTER"><h1 class="chapter"><a class="title" name="PUIS-CHP-27">27. Who Do You Trust?</A
></H1
><div class="htmltoc"><p><b>Contents:</B
><br><a class="SECT1" href="#PUIS-CHP-27-SECT-1" title="27.1 Can you Trust Your Computer?">Can you Trust Your Computer?</A
><br><a class="SECT1" href="ch27_02.htm#PUIS-CHP-27-SECT-2.4" title="27.2 Can You Trust Your Suppliers?">Can You Trust Your Suppliers?</A
><br><a class="SECT1" href="ch27_03.htm#PUIS-CHP-27-SECT-3.3" title="27.3 Can You Trust People?">Can You Trust People?</A
><br><a class="SECT1" href="ch27_04.htm" title="27.4 What All This Means">What All This Means</A
></P
><p></P
></DIV
><p class="para"><a class="indexterm" name="AUTOID-35645"></A
>Trust is the most
important quality in computer security. If you build a bridge, you
can look at the bridge every morning and make sure it's
still standing. If you paint a house, you can sample the soil and
analyze it at a laboratory to ensure that the paint isn't
causing toxic runoff. But in the field of computer security, most
of the tools that you have for determining the strength of your
defenses and for detecting break-ins reside on your computer itself.
Those tools are as mutable as the rest of your computer system.</P
><p class="para">When your computer tells you that nobody has broken through
your defenses, how do you know that you can trust what it is saying?</P
><div class="sect1"><h2 class="sect1"><a class="title" name="PUIS-CHP-27-SECT-1">27.1 Can you Trust Your Computer?</A
></H2
><p class="para"><a class="indexterm" name="AUTOID-35651"></A
>For
a few minutes, try thinking like a computer criminal. A few months
ago you were fired from Big Whammix, the large smokestack employer
on the other side of town, and now you're working for a
competing company, Bigger Bammers. Your job at Bammers is corporate
espionage; you've spent the last month trying to break
into Big Whammix's central mail server. Yesterday, you
discovered a bug in a version of <kbd class="command">sendmail</KBD
> [1]
that Whammix is running, and you gained superuser access.</P
><blockquote class="footnote"><p class="para">[1] This is
a safe enough bet&nbsp;- <kbd class="command">sendmail</KBD
> seems to have an endless supply
of bugs and design misfeatures leading to security problems.</P
></BLOCKQUOTE
><p class="para">What do you do now?</P
><p class="para">Your primary goal is to gain as much valuable corporate information
as possible, and to do so without leaving any evidence that would
allow you to be caught. But you have a secondary goal of masking
your steps, so that your former employers at Whammix will never
figure out that they have lost information.</P
><p class="para">Realizing that the hole in the Whammix <kbd class="command">sendmail</KBD
> daemon might
someday be plugged, you decide to create a new back door that you
can use to gain access to the company's computers in the
future. The easiest thing to do is to modify the computer's
<i class="filename">/bin/login</I
> program to accept
hidden passwords. Therefore, you take your own copy of the source
code to <i class="filename">login.c</I
> and modify it to allow anybody
to log in as root if they type a particular sequence of apparently
random passwords. Then you install the program as <i class="filename">/bin/passwd </I
>.</P
><p class="para">You want to hide evidence of your data collection, so you
also patch the<i class="filename"> /bin/ls </I
> program. When the program
is asked to list the contents of the directory in which you are
storing your cracker tools and intercepted mail, it displays none
of your files. You &quot;fix&quot; these programs so that
the checksums reported by <i class="filename"> /usr/bin/sum</I
> are
the same. Then, you manipulate the system clock or edit the raw
disk to set all the times in the inodes back to their original values,
to further cloak your modifications.</P
><p class="para">You'll be connecting to the computer on a regular
basis, so you also modify <i class="filename">/usr/bin/netstat</I
>
so that it doesn't display connections between the Big
Whammix IP subnet and the subnet at Bigger Bammers. You may also
modify the <i class="filename">/usr/bin/ps</I
> and <i class="filename">/usr/bin/who</I
>
programs, so that they don't list users who are logged
in via this special back door.</P
><p class="para">Content, you now spend the next five months periodically logging
into the mail server at Big Whammix and making copies of all of
the email directed to the marketing staff. You do so right up to
the day that you leave your job at Bigger Bammers and move on to
a new position at another firm. On your last day, you run a shell
script that you have personally prepared that restores all of the
programs on the hard disk to their original configuration. Then,
as a parting gesture, your program introduces subtle modifications
into the Big Whammix main accounting database.</P
><p class="para">Technological fiction? Hardly. By the middle of the 1990s,
attacks against computers in which the system binaries were modified
to prevent detection of the intruder had become commonplace. After
sophisticated attackers gain superuser access, the common way that
you discover their presence is if they make a mistake.</P
><div class="sect2"><h3 class="sect2"><a class="title" name="PUIS-CHP-27-SECT-1.1">27.1.1 Harry's Compiler</A
></H3
><p class="para">In the early days of the <span class="acronym">MIT</SPAN
> Media Lab,
there was a graduate student who was very unpopular with the other
students in his lab. To protect his privacy, we'll call
the unpopular student &quot;Harry.&quot;</P
><p class="para">Harry was obnoxious and abrasive, and he wasn't a
very good programmer either. So the other students in the lab decided
to play a trick on him. They modified the <span class="acronym">PL/1</SPAN
>
compiler on the computer that they all shared so that the program
would determine the name of the person who was running it. If the
person running the compiler was Harry, the program would run as
usual, reporting syntax errors and the like, but it would occasionally,
randomly, not produce a final output file.</P
><p class="para">This mischievous prank caused a myriad of troubles for Harry.
He would make a minor change to his program, run it, and&nbsp;- occasionally&nbsp;- the
program would run the same way as it did before he made his modification.
He would fix bugs, but the bugs would still remain. But then, whenever
he went for help, one of the other students in the lab would sit
down at the terminal, log in, and everything would work properly.</P
><p class="para">Poor Harry. It was a cruel trick. Somehow, though, everybody
forgot to tell him about it. He soon grew frustrated with the whole
enterprise, and eventually left school.</P
><p class="para">And you thought those random &quot;bugs&quot; in your
system were there by accident?</P
></DIV
><div class="sect2"><h3 class="sect2"><a class="title" name="PUIS-CHP-27-SECT-1.2">27.1.2 Trusting Trust</A
></H3
><p class="para">Perhaps the definitive account of the problems inherent in
computer security and trust is related in Ken Thompson's
article, &quot;Reflections on Trusting Trust.&quot; [2]
Thompson describes a back door planted in an early research version
of <span class="acronym">UNIX</SPAN
>.</P
><blockquote class="footnote"><p class="para">[2] <em class="emphasis">Communications of the ACM</EM
>, Volume 27, Number 8, August 1984.</P
></BLOCKQUOTE
><p class="para">The <a class="indexterm" name="AUTOID-35691"></A
><a class="indexterm" name="AUTOID-35693"></A
>
back door was a modification to the <i class="filename">/bin/login </I
><a class="indexterm" name="AUTOID-35698"></A
>
program
that would allow him to gain superuser access to the system at any
time, even if his account had been deleted, by providing a predetermined
username and password. While such a modification is easy to make,
it's also an easy one to detect by looking at the computer's
source code. So Thompson modified the computer's C compiler
to detect if it was compiling the <i class="filename">login.c</I
> program.
If so, then the additional code for the back door would automatically
be inserted into the object-code stream, even though the code was
not present in the original C source file.</P
><p class="para">Thompson could now have the <i class="filename">login.c program</I
> inspected by his
coworkers, compile the program, install the <i class="filename">/bin/login</I
>
executable, and yet be assured that the back door was firmly in
place.</P
><p class="para">But what if somebody inspected the source code for the C compiler
itself? Thompson thought of that case as well. He further modified
the C compiler so that it would detect whether it was compiling
the source code for itself. If so, the compiler would automatically
insert the special program recognition code. After one more round
of compilation, Thompson was able to put all the original source
code back in place.</P
><p class="para">Thompson's experiment was like a magic trick. There
was no back door in the <i class="filename">login.c </I
>source file
and no back door in the source code for the C compiler, and yet
there was a back door in both the final compiler and in the <i class="filename">login</I
>
program. Abracadabra!</P
><p class="para">What hidden actions do your compiler and <i class="filename">login</I
>
programs perform?</P
></DIV
><div class="sect2"><h3 class="sect2"><a class="title" name="PUIS-CHP-27-SECT-1.3">27.1.3 What the Superuser Can and Cannot Do</A
></H3
><p class="para"><a class="indexterm" name="AUTOID-35713"></A
><a class="indexterm" name="AUTOID-35716"></A
>As all of these examples illustrate, technical expertise
combined with superuser privileges on a computer is a powerful combination.
Together, they let an attacker change the very nature of the computer's
operating system. An attacker can modify the system to create &quot;hidden&quot;
directories that don't show up under normal circumstances
(if at all). Attackers can change the system clock, making it look
as if the files that they modify today were actually modified months
ago. An attacker can forge electronic mail. (Actually, anybody can
forge electronic mail, but an attacker can do a better job of it.)</P
><p class="para">Of course, there are some things that an attacker cannot do,
even if that attacker is a technical genius and has full access
to your computer and its source code. An attacker cannot, for example,
decrypt a message that has been encrypted with a perfect encryption
algorithm. But he can alter the code to record the key the next
time you type it. An attacker probably can't program your
computer to perform mathematical calculations a dozen times faster
than it currently does, although there are few security implications
to doing so. Most attackers can't read the contents of
a file after it's been written over with another file unless
they take apart your computer and take the hard disk to a laboratory.
However, an attacker with privileges can alter your system so that
files you have deleted are still accessible (to him).</P
><p class="para">In each case, how do you tell if the attack has occurred?</P
><p class="para">The &quot;what-if&quot; scenario can be taken to considerable
lengths. Consider an attacker who is attempting to hide a modification
in a computer's <i class="filename">/bin/login</I
>
program:</P
><table class="table"><caption class="table"><a class="title" name="PUIS-CHP-27-TAB-1">Table 27.1: The &quot;What-If&quot;
Scenario</A
></CAPTION
><thead class="thead"><tr class="row" valign="TOP"><th class="entry" align="LEFT" rowspan="1" colspan="1"><p class="para">What the Attacker Might Do After Gaining
Root Access</P
></TH
><th class="entry" align="LEFT" rowspan="1" colspan="1"><p class="para">Your Responses</P
></TH
></TR
></THEAD
><tbody class="tbody"><tr class="row" valign="TOP"><td class="entry" rowspan="1" colspan="1"><p class="para">The attacker plants a back door in the
<i class="filename">/bin/login</I
> program to allow unauthorized access.</P
></TD
><td class="entry" rowspan="1" colspan="1"><p class="para">You use PGP to create a digital signature
of  all system programs. You check the signatures every day.</P
></TD
></TR
><tr class="row" valign="TOP"><td class="entry" rowspan="1" colspan="1"><p class="para">The attacker modifies the version of
PGP that you are using, so that it will report that the signature
on <i class="filename">/bin/login </I
>verifies, even if it doesn't.</P
></TD
><td class="entry" rowspan="1" colspan="1"><p class="para">You copy <i class="filename">/bin/login </I
>onto
another computer before verifying it with a trusted copy of PGP.</P
></TD
></TR
><tr class="row" valign="TOP"><td class="entry" rowspan="1" colspan="1"><p class="para">The attacker modifies your computer's
kernel by adding loadable modules, so that when the<i class="filename"> /bin/login</I
>
is sent through a TCP connection, the original <i class="filename">/bin/login,</I
>
rather than the modified version, is sent.</P
></TD
><td class="entry" rowspan="1" colspan="1"><p class="para">You put a copy of PGP on a removable
 hard disk. You mount the hard disk to  perform the signature
verification and then  unmount it. Furthermore, you put a good
 copy of <i class="filename">/bin/login </I
>onto your removable
 hard disk and then copy the good program  over the installed
version on a regular  basis.</P
></TD
></TR
><tr class="row" valign="TOP"><td class="entry" rowspan="1" colspan="1"><p class="para">The attacker regains control of your
system and further modifies the kernel so that the modification
to <i class="filename">/bin/login</I
> is patched into the running program
after it loads. Any attempt to read the contents of the
<i class="filename">/bin/login</I
> file results in the original,
unmodified version.</P
></TD
><td class="entry" rowspan="1" colspan="1"><p class="para">You reinstall the entire system software,
 and configure the system to boot from a  read-only device
such as a CD-ROM.</P
></TD
></TR
><tr class="row" valign="TOP"><td class="entry" rowspan="1" colspan="1"><p class="para">Because the system now boots from a CD-ROM,
you cannot easily update system software as bugs are discovered.
The attacker waits for a bug to crop up in one of your installed
programs, such as sendmail. When the bug is reported, the attacker
will be ready to pounce.</P
></TD
><td class="entry" rowspan="1" colspan="1"><p class="para">Your move . . .</P
></TD
></TR
></TBODY
></TABLE
><p class="para">(See <a class="xref" href="#PUIS-CHP-27-TAB-1" title='The "What-If&quot; Scenario'>Table 27.1</A
>.)</P
><p class="para">If you think that this description sounds like a game of chess,
you're correct. Practical computer security is a series
of actions and counteractions, of attacks and defenses. As with
chess, success depends upon anticipating your opponent's
moves and planning countermeasures ahead of time. Simply reacting
to your opponent's moves is a recipe for failure.</P
><p class="para">The key thing to note, however, is that somewhere, at some
level, you need to trust what you are working with. Maybe you trust
the hardware. Maybe you trust the <span class="acronym">CD-ROM</SPAN
>. But
at some level, you need to trust what you have on hand. Perfect
security isn't possible, so we need to settle for the next
best thing&nbsp;- reasonable trust on which to build.</P
><p class="para">The question is, where do you place that trust?<a class="indexterm" name="AUTOID-35774"></A
><a class="indexterm" name="AUTOID-35777"></A
><a class="indexterm" name="AUTOID-35780"></A
></P
></DIV
></DIV
></DIV
><div class="htmlnav"><p></P
><hr align="LEFT" width="515" title="footer"><table width="515" border="0" cellspacing="0" cellpadding="0"><tr><td align="LEFT" valign="TOP" width="172"><a class="SECT1" href="ch26_04.htm#PUIS-CHP-26-SECT-4.6" title="26.4 Other Liability"><img src="../gifs/txtpreva.gif" alt="Previous: 26.4 Other Liability" border="0"></A
></TD
><td align="CENTER" valign="TOP" width="171"><a class="book" href="index.htm" title="Practical UNIX &amp; Internet Security"><img src="../gifs/txthome.gif" alt="Practical UNIX &amp; Internet Security" border="0"></A
></TD
><td align="RIGHT" valign="TOP" width="172"><a class="SECT1" href="ch27_02.htm#PUIS-CHP-27-SECT-2.4" title="27.2 Can You Trust Your Suppliers?"><img src="../gifs/txtnexta.gif" alt="Next: 27.2 Can You Trust Your Suppliers?" border="0"></A
></TD
></TR
><tr><td align="LEFT" valign="TOP" width="172">26.4 Other Liability</TD
><td align="CENTER" valign="TOP" width="171"><a class="index" href="index/idx_0.htm" title="Book Index"><img src="../gifs/index.gif" alt="Book Index" border="0"></A
></TD
><td align="RIGHT" valign="TOP" width="172">27.2 Can You Trust Your Suppliers?</TD
></TR
></TABLE
><hr align="LEFT" width="515" title="footer"><p class="nav"><font size="-1">[ <a href="../index.htm" title="The Networking CD Bookshelf">Library Home</A
> | <a href="../dnsbind/index.htm" title="DNS &amp; BIND">DNS &amp; BIND</A
> | <a href="../tcpip/index.htm" title="TCP/IP Network Administration">TCP/IP</A
> | <a href="../sendmail/index.htm" title="sendmail">sendmail</A
> | <a href="../smdref/index.htm" title="sendmail Desktop Reference">sendmail Reference</A
> | <a href="../firewall/index.htm" title="Building Internet Firewalls">Firewalls</A
> | <a href="index.htm" title="Practical UNIX &amp; Internet Security">Practical Security</A
> ]</FONT
></P
></DIV
></BODY
></HTML
>
