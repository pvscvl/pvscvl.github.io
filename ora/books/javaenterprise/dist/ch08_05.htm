<html>
<head>
<title>Bandwidth Management (Java Distributed Computing)</title>

<!-- STYLESHEET -->

<link rel="stylesheet" type="text/css" href="../style/style1.css" webstripperlinkwas="../style/style1.css">

<!-- METADATA -->



<!--Dublin Core Metadata-->

<meta name="DC.Creator" content="Jim Farley">
<meta name="DC.Date" content="">
<meta name="DC.Format" content="text/xml" scheme="MIME">
<meta name="DC.Generator" content="XSLT stylesheet, xt by James Clark">
<meta name="DC.Identifier" content="">
<meta name="DC.Language" content="en-US">
<meta name="DC.Publisher" content="O'Reilly &amp; Associates, Inc.">
<meta name="DC.Source" content="1-56592-206-9E" scheme="ISBN">
<meta name="DC.Subject.Keyword" content="">
<meta name="DC.Title" content="Bandwidth Management">
<meta name="DC.Type" content="Text.Monograph">

</head>

<body>

<!-- START OF BODY -->



<!-- TOP BANNER -->

<a href="index.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/dist/index.htm"><img src="gifs/smbanner.gif" webstripperlinkwas="gifs/smbanner.gif" usemap="#banner-map" border="0" alt="Book Home"></a>
<map name="banner-map"><map name="banner-map"> <area shape="rect" coords="0,0,466,65" href="index.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/dist/index.htm" alt="Java Distributed Computing"> <area shape="rect" coords="467,0,514,18" href="jobjects/fsearch.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/dist/jobjects/fsearch.htm" alt="Search this book"> </map>
</map>

<!-- TOP NAV BAR -->

<div class="navbar">
<table width="515" border="0">
<tr>
<td align="left" valign="top" width="172"><a href="ch08_04.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/dist/ch08_04.htm"><img src="../gifs/txtpreva.gif" webstripperlinkwas="../gifs/txtpreva.gif" alt="Previous" border="0"></a></td><td align="center" valign="top" width="171"><a href="ch08_01.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/dist/ch08_01.htm">Chapter 8: Bandwidth-Limited Systems</a></td><td align="right" valign="top" width="172"><a href="ch09_01.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/dist/ch09_01.htm"><img src="../gifs/txtnexta.gif" webstripperlinkwas="../gifs/txtnexta.gif" alt="Next" border="0"></a></td>
</tr>
</table>
</div>
<hr width="515" align="left">

<!-- SECTION BODY -->
<h2 class="sect1">8.5. Bandwidth Management</h2>

<p>
<a name="INDEX-1175"></a><a name="INDEX-1176"></a>Armed with a basic ability to
monitor our data throughput over time, we can now discuss how to use
this information to effectively manage the available bandwidth.
</p>

<p>The general principle behind bandwidth management is to optimize the
use of the available bandwidth to satisfy certain requirements of the
system. The nature of these requirements varies greatly from one
application to the next, and so do the approaches used to manage
bandwidth. The general approach is to assess the performance of the
system in terms of data input and output rates, content conversion
rates, and computation times. Based on this assessment, we can try to
adjust resource allocations to improve the overall performance of the
system.
</p>

<p>In order to demonstrate some of the ways that bandwidth can be
managed, we'll first look at how a streaming audio agent would
be implemented. In many ways, streaming audio is a worst-case
scenario for bandwidth-limited applications, since there are heavy
real-time constraints as well as computation requirements. After
this, we will look at implementing a component of a Java-based WWW
browser, to see how bandwidth can be managed across multiple input
streams to maximize perceived performance.
</p>

<a name="JDP-CH-8-SECT-5.1"></a>
<h3 class="sect2">8.5.1. Streaming Multimedia</h3>

<p>
<a name="INDEX-1177"></a><a name="INDEX-1178"></a><a name="INDEX-1179"></a><a name="INDEX-1180"></a><a name="INDEX-1181"></a>In this case, the primary purpose of
the local agent is to receive multimedia data from the network,
process it as needed to convert it to a format suitable for
presentation, and present the multimedia data to the user. The
driving factor is optimizing the presentation to the user. We want
audio to play without skips, video to play as smoothly and
consistently as possible, and graphics to display when they are
supposed to in the overall presentation. Typically, we also need the
audio, video, and graphics display to be synchronized with each
other, and to maintain that synchronization even if some data is late
arriving.
</p>

<p>In order to focus on the basic issues at play here, let's look
at the simplest case: a single stream of media data being received in
a low-bandwidth environment for real-time playback. This is a
particularly relevant example, since modem-rate audio streaming has
become so popular on the Web. The audio samples are typically
compressed before being transmitted, so the audio receiver must
decode the compressed data into audio samples before playing them on
the local audio device. Using our
<tt class="literal">ContentConsumer</tt> and
<tt class="literal">ContentProducer</tt> classes, we can define a
<tt class="literal">StreamProducer</tt> extension of
<tt class="literal">ContentProducer</tt> that simply provides a
<tt class="literal">ContentProducer</tt> interface to an
<tt class="literal">InputStream</tt>. In our application, this
<tt class="literal">StreamProducer</tt> acts as a source of compressed
audio data. The <tt class="literal">AudioProducer</tt><a name="INDEX-1182"></a> is a
<tt class="literal">ContentProducer</tt> extension that generates audio
samples from compressed audio data by decoding the compressed data.
We set its source to be the <tt class="literal">StreamProducer</tt> that
we just wrapped around our <tt class="literal">RTInputStream</tt>.
Finally, we define an <tt class="literal">AudioConsumer</tt><a name="INDEX-1183"></a> extension of
<tt class="literal">Content-Consumer</tt> that consumes audio samples by
sending them to the local audio device. We won't bother
implementing these subclasses yet; for now we only need to note that
they extend the <tt class="literal">ContentConsumer</tt> and
<tt class="literal">ContentProducer</tt> interfaces.
</p>

<p>With these classes in hand, our streaming audio playback might be
implemented along the following lines:
</p>

<blockquote>
<pre class="programlisting">// Get the audio input stream, typically from a Socket connection with 
// a server. 
InputStream audioIn = ...
// Wrap it with a real-time stream so we can monitor data throughput
// off of the wire
RTInputStream rtAudioIn = new RTInputStream(audioIn);
// Make our audio pipeline:
//         compressed audio -&gt; raw audio -&gt; audio device
StreamProducer stProd = new StreamProducer(rtAudioIn);
AudioProducer audioProd = new AudioProducer();
audioProd.setSource(stProd);
String audioFileSpec = "/dev/audio";
AudioConsumer audioCons = new AudioConsumer(audioFileSpec);
audioCons.setSource(audioProd);
// Start playback
audioCons.consumeAll();</pre>
</blockquote>

<p>Here we simply take our source of raw data, in the form of an
<tt class="literal">InputStream</tt>, wrap it with an
<tt class="literal">RTInputStream</tt> to allow us to monitor the input
data rate, then wrap it with a <tt class="literal">StreamProducer</tt> so
that we can build up the rest of the pipeline. We create an
<tt class="literal">AudioProducer</tt> and set the
<tt class="literal">StreamProducer</tt> as its source, then create an
<tt class="literal">AudioConsumer</tt> pointing to an appropriate local
device driver and set the <tt class="literal">AudioProducer</tt> as its
source. To begin the streaming playback, we simply call the
<tt class="literal">consumeAll()</tt> method on the
<tt class="literal">AudioConsumer</tt>, which causes it to call the
<tt class="literal">produce()</tt> method on its source, and so on up the
pipeline until the <tt class="literal">StreamProducer</tt> does a read on
its <tt class="literal">InputStream</tt>. All along the pipeline, we are
maintaining data throughput measurements using the facilities built
into our <tt class="literal">RTInputStream</tt>,
<tt class="literal">ContentConsumer</tt>, and
<tt class="literal">ContentProducer</tt> classes.
</p>

<p>The input stream is something that we have little control over, so we
can do little at that stage of our pipeline besides monitoring the
input data rate using the <tt class="literal">RTInputStream</tt>. There
are some <a name="INDEX-1184"></a><a name="INDEX-1185"></a>
data buffering issues that we have to deal with in the other stages,
however. Let's start with the tail end of the pipeline, the
<tt class="literal">AudioConsumer</tt>. Most audio devices on computers
have a small internal data buffer in which to hold audio samples.
Since in most cases an application can feed audio data to the device
much faster than it can play the samples back in real time, our
<tt class="literal">AudioConsumer</tt> needs to provide some external
data buffering. For example, assuming that our audio device accepts
16-bit audio samples from an audio stream that was sampled at CD
rates (e.g., 44,000 samples per second), the audio device plays back
data at 44,000 x 2 = 88kB/s. Assuming a ready supply of audio data,
such as a local audio file, this data rate will be well exceeded by
the application feeding the audio device. So our
<tt class="literal">AudioConsumer</tt> class will have to buffer audio
samples when the audio device has filled its internal data buffers.
Its
<tt class="literal">doConsume()</tt><a name="INDEX-1186"></a> implementation may look something like
the following:
</p>

<blockquote>
<pre class="programlisting">public boolean doConsume(byte data[]) {
    // If we already have data queued in our local buffer, then
    // put this new data into the end of the queue and pull the
    // first data out of the queue
    if (!buffer.isEmpty()) {
        buffer.append(data);
        data = buffer.remove();
    }

    // Try to write the data to the audio device
    int numBytes = device.write(data);
    if (numBytes &lt; data.length) {
        // Add any remaining bytes to the beginning of our 
        // local buffer
        byte newBuf = new byte[data.length - numBytes];
        System.arraycopy(data, numBytes, newBuf, 0, newBuf.length);
        buffer.prepend(newBuf);
    }

    if (numBytes &gt; 0)
        return true;
    else
        return false;
}</pre>
</blockquote>

<p>We assume that <tt class="literal">device</tt> is a data member of the
<tt class="literal">AudioConsumer</tt> class that represents an interface
to the audio device driver, and that <tt class="literal">buffer</tt> is
another data member that is some sort of storage class for holding
data arrays.
</p>

<p>The workhorse of our audio pipeline is the
<tt class="literal">AudioProducer</tt> class, and it's here that
our data throughput monitoring will be the most useful. The
<tt class="literal">AudioProducer</tt> must take the compressed audio
data stream, decompress the data, and pass the audio samples on to
the <tt class="literal">AudioConsumer</tt>. It will also have to maintain
its own data buffer for compressed audio data, for the same reasons
that the <tt class="literal">AudioConsumer</tt> needs to maintain its own
data buffer. A given amount of compressed audio data will take some
amount of time to be transmitted over the network and be fed to the
<tt class="literal">AudioProducer</tt>. It also takes some non-finite
amount of time for the <tt class="literal">AudioProducer</tt> to decode a
chunk of compressed audio data into audio samples, and some time for
the audio device to consume this data (e.g., to play the audio
samples). Ideally, we want the audio playback to be continuous and
free from skips or blank spots, since these are very noticeable to
even the casual listener. The <tt class="literal">AudioProducer</tt>
needs a data buffer so that it can maintain a constant flow of audio
samples to the <tt class="literal">AudioConsumer</tt> regardless of the
rates at which compressed data is fed into the producer, or audio
samples are pulled out of the producer by the consumer. Our streaming
audio pipeline now looks like <a href="#JDP-CH-8-FIG-1">Figure 8-1</a>, with a
compressed audio data buffer on the
<tt class="literal">AudioProducer</tt>.
</p>

<a name="JDP-CH-8-FIG-1"></a>
<div class="figure">
<img alt="figure" src="figs/jdc_0801.gif" webstripperlinkwas="figs/jdc_0801.gif"></div>
<h4 class="objtitle">Figure 8-1. Streaming audio pipeline</h4>

<p>Suppose the input stream of compressed audio starts, and we let the
<tt class="literal">AudioProducer</tt> begin decompressing data and
immediately pass it on to the <tt class="literal">AudioConsumer</tt>
before moving on to the next chunk of compressed audio data, with no
data buffering. If the <tt class="literal">AudioConsumer</tt> finishes
playing the first set of audio samples before the
<tt class="literal">AudioProducer</tt> is ready with the next set, then
we will hear a gap in the audio playback. This can happen if the
compressed data stream slows down to the point that the time to
download and decode a given amount of compressed audio is greater
than the time for the resulting audio samples to be played. It can
also happen if the local CPU resources become scarce (i.e., the user
has started an intensive spreadsheet calculation while listening to
the audio clip). In this case, the additional decode time makes the
<tt class="literal">AudioProducer</tt>'s data production rate lag
behind the <tt class="literal">AudioConsumer</tt>'s consumption
rate, and we hear gaps in the audio again.
</p>

<p>So now that we've justified the need for both the
<tt class="literal">AudioProducer</tt> and the
<tt class="literal">AudioConsumer</tt> to have data buffers, we need to
decide how much data to buffer at each stage. We'll assume that
the <tt class="literal">AudioConsumer</tt> will be the simpleton in the
pipeline, and that it will simply buffer any data that the audio
device can't buffer itself. This allows us to concentrate on
the <tt class="literal">AudioProducer </tt>as the main data manager in
the pipeline.
</p>

<p>When the <tt class="literal">AudioProducer</tt> starts reading from the
input stream, it doesn't know how fast to expect the compressed
data to arrive, or how long it will take to decode the compressed
data into audio samples. For this reason, the
<tt class="literal">AudioProducer</tt> needs to read and decode some
compressed data in order to gauge the effective bandwidth of the
network connection and the rate at which the producer can output
audio samples to the consumer; from this information
<tt class="literal">AudioProducer</tt> estimates a safe data buffer size.
During playback, it also needs to check the input rate of compressed
data, and its own output data rate, to see if conditions warrant a
change in the buffer size. A noticeable drop in the input rate may
warrant a pause in the playback while the
<tt class="literal">AudioProducer</tt> fills a larger buffer so that the
remainder of the audio clip can be played without interruption. The
same applies when local CPU resources have become scarce because
other applications are starting or becoming more active, thus slowing
the rate at which the <tt class="literal">AudioProducer</tt> can decode
audio samples.<a name="INDEX-1187"></a><a name="INDEX-1188"></a>
</p>

<p>A partial implementation of our <tt class="literal">AudioProducer</tt> is
shown in <a href="#JDP-CH-8-EX-7">Example 8-6</a>. We have not included the
implementation of the audio decode algorithm, and we have also left
out the implementation of the buffer manipulation routines, since
their intended operation is obvious from their use in the rest of the
class implementation.
<a name="INDEX-1189"></a>
</p>

<a name="JDP-CH-8-EX-7"></a>
<div class="example">
<h4 class="objtitle">Example 8-6. The AudioProducer Class</h4>
<blockquote>
<pre class="programlisting">package dcj.examples.Bandwidth;

import dcj.util.Bandwidth.*;
import java.io.InputStream;
import java.io.OutputStream;

public class AudioProducer extends ContentProducer
{
  byte[] buffer = null;
  long maxBuffer = 0;
  long sampleRate;

  // Buffer operations...
  protected void appendToBuffer(byte[] data);
  protected byte[] removeFromBuffer(long size);

  // Method for computing new buffer size based on input
  // data rate, our production rate, and the audio sample rate
  protected void resizeBuffer(float inRate, float outRate,
                              long audioRate);

  // Method that decodes a given chunk of compressed data into
  // audio samples.
  protected byte[] decode(byte[] cData);

  public boolean produceAll() {
    if (buffer == null) {
      int maxLoop = 10;
      long bytesPerLoop = 512;
      for (int loop = 0; loop &lt; maxLoop; loop++) {
        byte[] data = produce(bytesPerLoop);
        appendToBuffer(data);
      }

      // Assuming we know the rate at which data is required by the
      // AudioConsumer (i.e., the sample rate of the audio), then
      // estimate the buffer size needed for continuous playback
      resizeBuffer(source.getAverageRate(), monitor.getAverageRate(),
                   sampleRate);
    }

    boolean success = false;
    if (dest != null) {
      byte[] data = produce();
      while (data != null) {
        success = dest.consume(data);

        // Re-estimate buffer size
        resizeBuffer(source.getLastRate(), monitor.getLastRate(),
                     sampleRate);
        if (success)
          data = produce();
        else
          data = null;
      }
    }

    return success;
  }

  protected byte[] doProduction(long limit) {
    byte[] sData = null;

    // Ask our source for compressed data, and decode it.
    if (source != null) {
      sData = source.produce(limit);
    }
    byte[] audioData = decode(sData);

    // If our buffer is not full, add the new data to it
    if (buffer.length &lt; maxBuffer) {
      appendBuffer(audioData);
    }

    // If our buffer is now full, then return the requested
    // amount of data, else return nothing.
    if (buffer.length &gt; maxBuffer) {
      audioData = removeFromBuffer(limit);
    }
    else
      audioData = null;

    return audioData;
  }
}</pre>
</blockquote>
</div>

<p>Our <tt class="literal">AudioProducer</tt> class extends the
<tt class="literal">ContentProducer</tt> class by reimplementing the
<tt class="literal">produceAll()</tt><a name="INDEX-1190"></a> and <tt class="literal">doProduction()</tt>
methods to deal with the data buffering requirements of our
application. The <tt class="literal">produceAll()</tt> implementation has
the same basic structure as the implementation in the
<tt class="literal">ContentProducer</tt> class, but here the method is
also responsible for initializing the data buffer to a size that
matches the environment it encounters when first called. The first
time <tt class="literal">produceAll()</tt> is called, the data buffer has
not yet been initialized, so the <tt class="literal">AudioProducer</tt>
must first process some data in order to gauge the expected input and
output data rates. It does this by requesting a series of data chunks
from the input stream and decoding them by calling its own
<tt class="literal">produce()</tt> method. In this case, we use ten
chunks of compressed data of 512 bytes each to gauge the throughput,
but we could use a single larger chunk of data, or many small chunks
of data. The important thing is to try to match the expected
interaction with the input stream and decoder as much as possible. We
chose a set of medium-size chunks of data because we will be running
the producer this way in full operation--get some data from the
input stream, decode it, and either buffer it or hand it off to the
<tt class="literal">AudioConsumer</tt>. We typically won't be
asking for the entire audio clip before decoding it, since the
driving requirement is that we want to stream audio data and play it
back in real time. We also don't want to fragment the clip into
chunks that are too small because the setup time for the decoder will
start to affect the throughput rate.
</p>

<p>When we have an initial estimate for the buffer size, the
<tt class="literal">AudioProducer</tt> starts requesting data from the
input stream and producing audio samples by calling its
<tt class="literal">produce()</tt> method. After each produce/consume
cycle, the <tt class="literal">produceAll()</tt> method recalculates the
required buffer size by calling the <a name="INDEX-1191"></a><tt class="literal">resizeBuffer()</tt>
method again. We do this to track changes in the network bandwidth
and the local environment. If the input rate from the network or the
output rate from the decoder drops too low, we want to increase the
data buffer. If the change is dramatic, this may mean pausing the
playback while the buffer fills with data; if this prevents a series
of interruptions later, then it is worth it in terms of playback
quality.<tt class="literal"></tt><a name="INDEX-1192"></a>
</p>

<p>The
<tt class="literal">doProduction()</tt><a name="INDEX-1193"></a> method manages the data buffer. It
first requests compressed data from the input stream, then sends the
data through the decoder. If the buffer is not full, then the audio
samples are appended to the buffer. If the buffer is full, then the
requested amount of data is pulled from the buffer and returned.
</p>

<p>On the server side, the bandwidth monitoring and management
requirements are generally simpler, but can be made as complex as we
would like. The primary requirement of the audio server is to send
data over the network as quickly as possible, so that the client has
a chance of playing the audio back in real time. If we are sending a
pre-encoded data file, we may not even need a server agent; a simple
file transfer is all that's required, assuming that the file
system and the network I/O on the server is optimized to send data as
quickly as possible. If we're streaming a live audio feed, the
server will have to encode the audio stream as it is generated and
send the compressed data over the network to the client. Again,
assuming that the encoding scheme and the network connection are both
fixed, there is not much the server agent can do to improve the
situation if the network bandwidth to the client starts to degrade.
</p>

<p>However, many client/server audio systems these days are designed to
provide variable-bandwidth capabilities, so that the server can
respond to the changing nature of the network connection. Typically,
the server and the client engage in a bandwidth assessment period,
much like the beginning of the <tt class="literal">produceAll()</tt>
method in our <tt class="literal">AudioProducer</tt>. Once the expected
bandwidth is known, then an encoding scheme with a given level of
compression is chosen so that enough data will reach the client to
allow constant playback. If the bandwidth changes significantly
during the data streaming, then the client and server can renegotiate
a new encoding scheme. The server alters its encoding process and
begins sending compressed data in the new format; the client then
alters its decoding process to handle the new format.<a name="INDEX-1194"></a><a name="INDEX-1195"></a><a name="INDEX-1196"></a><a name="INDEX-1197"></a>
</p>


<a name="JDP-CH-8-SECT-5.2"></a>
<h3 class="sect2">8.5.2. Web Browsing</h3>

<p>
<a name="INDEX-1198"></a><a name="INDEX-1199"></a><a name="INDEX-1200"></a><a name="INDEX-1201"></a>One application that is often
bandwidth-limited, but has very different constraints and goals from
streaming audio, is viewing web pages. In this case, maintaining a
constant stream of data to the final content consumer is not
essential (unless the page has streaming audio incorporated). What is
more important is allocating bandwidth to download page elements that
are of most interest to the viewer, leaving the other elements to be
downloaded later, or at a slower rate.
</p>

<p>Let's suppose that we are asked to implement a web browser in
Java. For discussion purposes, we'll ignore the initialization
of the HTTP connection, and the download of the HTML code making up
the requested page. We'll concentrate only on the next stage in
loading a page, which is downloading all the media elements
referenced in the page, such as images used for headers, icons, and
figures. Our goal is to make it look like the page's images and
other media elements are loading as fast as possible. In order to do
that, we'll distinguish between elements of the page that the
user is focusing on, and those that he isn't. If we take the
whole HTML page and consider the segment that is inside the scrolling
window of the user's web browser, as shown in <a href="#JDP-CH-8-FIG-2">Figure 8-2</a>, then the focus elements are all of those
media elements that lie inside of the scrolling browser window.
</p>

<a name="JDP-CH-8-FIG-2"></a>
<div class="figure">
<img alt="figure" src="figs/jdc_0802.gif" webstripperlinkwas="figs/jdc_0802.gif"></div>
<h4 class="objtitle">Figure 8-2. Focused and unfocused elements on a web page</h4>

<p>
<a href="#JDP-CH-8-EX-8">Example 8-7</a> shows an
<tt class="literal">HTMLPageLoader</tt><a name="INDEX-1202"></a> class that manages the loading of a
set of HTML page elements. These page elements are given to the
<tt class="literal">HTMLPageLoader</tt> in the form of
<tt class="literal">URL</tt> objects created by some outside agent, such
as a web browser. The <tt class="literal">HTMLPageLoader</tt> maintains
three lists of elements: one (<tt class="literal">elements</tt>) contains
all elements the loader has been asked to load; another
(<tt class="literal">focusElements</tt>) contains elements that are
within the user's current focus on the screen; and the third
(<tt class="literal">loadedElements</tt>) is a list of elements that have
been completely downloaded from their URL address. An external agent
can add elements to the <tt class="literal">HTMLPageLoader</tt> using the
<tt class="literal">addPageElements()</tt><a name="INDEX-1203"></a>
method, and it can move elements on and off of the focus list using
the <tt class="literal">focusElement()</tt> and
<tt class="literal">defocusElement()</tt><a name="INDEX-1204"></a><a name="INDEX-1205"></a> methods.
The <tt class="literal">loadElements()</tt> method is the workhorse of
the class, responsible for downloading the content of each element in
the page. The <tt class="literal">HTMLPageLoader</tt> class implements
the <tt class="literal">Runnable</tt> interface so that loading the page
elements can be performed in a separate thread from the agent that
monitors and updates the focus list. The <tt class="literal">run()</tt>
method simply calls <tt class="literal">loadElements()</tt>.
</p>

<a name="JDP-CH-8-EX-8"></a>
<div class="example">
<h4 class="objtitle">Example 8-7. An HTML Page Loader</h4>
<blockquote>
<pre class="programlisting">package dcj.examples.Bandwidth;

import dcj.util.Bandwidth.*;
import java.io.InputStream;
import java.lang.Runnable;

public class HTMLPageLoader implements Runnable {
  Vector elements;
  Vector focusElements;
  Vector loadedElements;
  boolean focusUpdate;
  Hashtable elementConsumers = new Hashtable;

  public void run() {
    loadElements();
  }

  public HTMLPageLoader(Vector urlList) {
    elements = urlList.clone();
  }

  public void addPageElement(URL addr) {
    elements.addElement(addr);
  }

  public void focusElement(URL addr) {
    synchronized (elements) {
      if (!elements.contains(addr)) {
        addPageElement(addr);
      }
    }

    synchronized (focusElements) {
      if (!focusElements.contains(addr)) {
        focusElements.addElement(addr);
      }
      focusUpdate = true;
    }
  }

  public defocusElement(URL addr) {
    synchronized (focusElements) {
      if (focusElements.removeElement(addr)) {
        focusUpdate = true;
      }
    }
  }

  public void loadElements() {
    Vector localFocus = null;
    boolean done = false;
    boolean changedFocus = false;
    Vector consumers;

    synchronized (focusElements) {
      if (!focusElements.isEmpty()) {
        localFocus = (Vector)focusElements.clone();
      }
    }

    synchronized (elements) {
      if (localFocus == null) {
        localFocus = elements.clone();
      }
    }

    while (!done) {
      Enumeration e = localFocus.elements();
      while (e.hasMoreElements()) {
        URL element = (URL)e.nextElement();
        ContentConsumer c = getConsumer(element);
        long byteCount = elementSize(element);
        // Consume a maximum of 5 percent of the entire element
        // in each loop.
        if (byteCount &gt; 20) {
          byteCount = byteCount / 20;
        }
        c.consume(byteCount);
        if (isComplete(element)) {
          doneElements.addElement(element);
          focusElements.removeElement(element);
          localFocus.removeElement(element);
        }
      }

      synchronized (focusElements) {
        if (focusUpdate) {
          localFocus = focusElements.clone();
          focusUpdate = false;
          changedFocus = true;
        }
      }

      if (focusElements.isEmpty()) {
        // No focus elements left, so we're either done loading
        // the region the user is looking at, or we've finished
        // the entire page.
        if (doneElements.size() == elements.size()) {
          done = true;
        }
        else {
          localFocus = elements;
        }
      }
    }
  }

  protected Vector getConsumer(URL item) {
    ContentConsumer c;
    // If the element has a consumer already,
    // add it to the list.
    if (elementConsumers.contains(item)) {
      c = (ContentConsumer)elementConsumers.get(item);
    }
    else {
      try {
        InputStream in = item.openStream();
        StreamProducer sp = new StreamProducer(in);
        c = makeConsumerFor(item);
        c.setSource(sp);
        elementConsumers.put(item, c);
      }
      catch (Exception e) { }
    }

    return c;
  }
}</pre>
</blockquote>
</div>

<p>The first thing the <tt class="literal">HTMLPageLoader</tt> does in its
<tt class="literal">loadElements()</tt><a name="INDEX-1206"></a>
method is check its focus list. If there are any elements on this
list, these will be loaded first. If there are no focus elements, the
loader takes the entire element list and begins loading them all.
After initializing its hotlist, the
<tt class="literal">loadElements()</tt> method enters a loop, loading
chunks of the page elements until they are completely downloaded.
Within the loop, the consumer for each element is obtained by calling
the
<tt class="literal">getConsumer()</tt><a name="INDEX-1207"></a>
method. In the <tt class="literal">getConsumer()</tt> method, if a given
element does not have a consumer already associated with it in the
hashtable, one is generated and put into the hashtable. Each of the
consumers associated with hotlist elements is then asked to consume a
chunk of data for its element. If any of the elements are complete,
the element is added to the "done" list. A check is made
to see if the focus list has changed. If it has, the hotlist of
elements is set to the current focus elements. If the list of focus
elements is empty, we've either loaded all of the focus
elements and can move on to the other page elements, or the page is
completely loaded. If there are still unloaded elements, the hotlist
is set to these elements. If not, the <tt class="literal">done</tt> flag is
set to <tt class="literal">true</tt>, causing the
<tt class="literal">loadElements()</tt> method to
return.
</p>

<p>The <tt class="literal">HTMLPageLoader</tt> class may be used in practice
by a web browser as a separate I/O thread, running in parallel with a
user interface thread that is redisplaying the page as the user
scrolls up and down. The <tt class="literal">HMTLPageLoader</tt> thread
is created once the URL elements of the page to be loaded have been
determined:
</p>

<blockquote>
<pre class="programlisting">Vector urls = ...
HTMLPageLoader loader = new HTMLPageLoader(urls);
Thread loaderThread = new Thread(loader);
loaderThread.start();</pre>
</blockquote>

<p>
<a name="INDEX-1208"></a>We could also initialize the list of
focus elements before starting the loader thread. The page display
component of the user interface can then have a
<tt class="literal">MouseMotionListener</tt> attached to it, which
listens for mouse motion events. This listener could implement its
<tt class="literal">mouseDragged()</tt><a name="INDEX-1209"></a>
method along these lines:
</p>

<blockquote>
<pre class="programlisting">public void mouseDragged(MouseEvent e) {
    HTMLPageLoader loader = getLoader();
    Rectangle focusArea =
        getFocusArea(e.getX(), e.getY(), e.getComponent());
    Vector urlList = getFocusItems(focusArea);
    loader.defocusElements();
    Enumeration e = urlList.elements();
    while (e.hasMoreElements()) {
        loader.focusElement((URL)e.nextElement());
    }
}</pre>
</blockquote>

<p>This will cause the <tt class="literal">HTMLPageLoader</tt> to allocate
the input bandwidth to the focus elements chosen by the
user.<tt class="literal"></tt><a name="INDEX-1210"></a>
</p>

<p>In this bandwidth-limited distributed application, we're not so
much concerned with actual throughput rates, but rather with the
relative amount of bandwidth allocated to different input streams in
order to optimize the user's <a name="INDEX-1211"></a><a name="INDEX-1212"></a><a name="INDEX-1213"></a><a name="INDEX-1214"></a> experience.<a name="INDEX-1215"></a><a name="INDEX-1216"></a>
</p>




<!-- BOTTOM NAV BAR -->

<hr width="515" align="left">
<div class="navbar">
<table width="515" border="0">
<tr>
<td align="left" valign="top" width="172"><a href="ch08_04.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/dist/ch08_04.htm"><img src="../gifs/txtpreva.gif" webstripperlinkwas="../gifs/txtpreva.gif" alt="Previous" border="0"></a></td><td align="center" valign="top" width="171"><a href="index.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/dist/index.htm"><img src="../gifs/txthome.gif" webstripperlinkwas="../gifs/txthome.gif" alt="Home" border="0"></a></td><td align="right" valign="top" width="172"><a href="ch09_01.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/dist/ch09_01.htm"><img src="../gifs/txtnexta.gif" webstripperlinkwas="../gifs/txtnexta.gif" alt="Next" border="0"></a></td>
</tr>
<tr>
<td align="left" valign="top" width="172">8.4. Monitoring Bandwidth</td><td align="center" valign="top" width="171"><a href="index/index.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/dist/index/index.htm"><img src="../gifs/index.gif" webstripperlinkwas="../gifs/index.gif" alt="Book Index" border="0"></a></td><td align="right" valign="top" width="172">9. Collaborative Systems</td>
</tr>
</table>
</div>
<hr width="515" align="left">

<!-- LIBRARY NAV BAR -->

<img src="../gifs/smnavbar.gif" webstripperlinkwas="../gifs/smnavbar.gif" usemap="#library-map" border="0" alt="Library Navigation Links"><p>
<font size="-1"><a href="copyrght.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/dist/copyrght.htm">Copyright &copy; 2001</a> O'Reilly &amp; Associates. All rights reserved.</font>
</p>
<map name="library-map"> <map name="library-map"> <area shape="rect" coords="-8,-5,72,97" href="../index.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/index.htm"> <area shape="rect" coords="75,2,150,109" href="../jenut/index.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/jenut/index.htm"> <area shape="rect" coords="154,0,225,99" href="../jnut/index.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/jnut/index.htm"> <area shape="rect" coords="228,3,298,112" href="../jfc/index.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/jfc/index.htm"> <area shape="rect" coords="306,1,373,124" href="../ebeans/index.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/ebeans/index.htm"> <area shape="rect" coords="380,2,446,115" href="../servlet/index.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/servlet/index.htm"> <area shape="rect" coords="452,1,524,101" href="../security/index.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/security/index.htm"> <area shape="rect" coords="528,2,610,102" href="index.htm" webstripperlinkwas="http://ext.rlab.cs.nyu.edu/~jsr/oreilly/dist/index.htm"> </map>
</map>

<!-- END OF BODY -->

</body>
</html>
